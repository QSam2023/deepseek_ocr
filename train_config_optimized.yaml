# DeepSeek OCR ä¼˜åŒ–è®­ç»ƒé…ç½®æ–‡ä»¶ - é’ˆå¯¹ A100 40GB GPU
# ä¼˜åŒ–ç›®æ ‡ï¼šæå‡GPUåˆ©ç”¨ç‡å’Œè®­ç»ƒé€Ÿåº¦

# æ•°æ®é…ç½®
data:
  # æ•°æ®æ ¹ç›®å½•
  data_root: "ocr_data"

  # åˆ’åˆ†åçš„æ•°æ®ç›®å½•ï¼ˆå¦‚æœä½¿ç”¨ç°æœ‰æ•°æ®ï¼‰
  split_data_dir: "ocr_data/splited_data"

  # æ˜¯å¦ä½¿ç”¨å·²å­˜åœ¨çš„åˆ’åˆ†æ•°æ®ï¼ˆTrue: ä½¿ç”¨å·²æœ‰æ•°æ®ï¼ŒFalse: é‡æ–°åˆ’åˆ†ï¼‰
  use_existing_split: false

  # æ•°æ®ç±»å‹é€‰æ‹©: 'all', 'table', 'stamp'
  data_type: "all"

  # æ•°æ®åˆ’åˆ†å‚æ•°ï¼ˆå½“ use_existing_split=false æ—¶ç”Ÿæ•ˆï¼‰
  train_ratio: 0.8
  split_seed: 42

# æ¨¡å‹é…ç½®
model:
  # æœ¬åœ°æ¨¡å‹è·¯å¾„
  model_path: "./deepseek_ocr"

  # æ˜¯å¦ä½¿ç”¨ 4bit é‡åŒ– (å»ºè®® A100 ä½¿ç”¨ False ä»¥è·å¾—æ›´å¥½æ€§èƒ½)
  load_in_4bit: false

  # æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼šä½¿ç”¨ unsloth ä¼˜åŒ–ç‰ˆæœ¬
  use_gradient_checkpointing: "unsloth"

  # å¼ºåˆ¶ç¼–è¯‘ä»¥è·å¾—æœ€ä½³æ€§èƒ½
  unsloth_force_compile: true

  # LoRA é…ç½®
  lora:
    # LoRA rank - å¯ä»¥é€‚å½“æé«˜ä»¥æå‡æ¨¡å‹å®¹é‡
    r: 32

    # LoRA alphaï¼ˆæ¨è alpha == rï¼‰
    lora_alpha: 32

    # LoRA dropout
    lora_dropout: 0.05

    # bias ç±»å‹
    bias: "none"

    # éšæœºç§å­
    random_state: 3407

    # ä½¿ç”¨ rsLoRA æå‡è®­ç»ƒç¨³å®šæ€§
    use_rslora: true

    # ç›®æ ‡æ¨¡å—
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"

# æ•°æ®å¤„ç†é…ç½®
data_processing:
  # å›¾åƒå°ºå¯¸ï¼ˆç”¨äºå›¾åƒ patchï¼‰
  image_size: 640

  # åŸºç¡€å°ºå¯¸ï¼ˆç”¨äºå…¨å±€è§†å›¾ï¼‰
  base_size: 1024

  # æ˜¯å¦ä½¿ç”¨åŠ¨æ€è£å‰ªï¼ˆé’ˆå¯¹å¤§å›¾ï¼‰
  crop_mode: true

  # æ˜¯å¦åªè®­ç»ƒå›å¤éƒ¨åˆ†ï¼ˆmask ç”¨æˆ· promptï¼‰
  train_on_responses_only: true

# è®­ç»ƒé…ç½® - é’ˆå¯¹ A100 40GB ä¼˜åŒ–
training:
  # è¾“å‡ºç›®å½•
  output_dir: "outputs"

  # ğŸš€ ä¼˜åŒ–ï¼šå¢åŠ  batch size ä»¥å……åˆ†åˆ©ç”¨ GPU å†…å­˜
  # A100 40GB å¯ä»¥æ”¯æŒæ›´å¤§çš„ batch size
  per_device_train_batch_size: 8

  # ğŸš€ ä¼˜åŒ–ï¼šå‡å°‘æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆå› ä¸º batch size å¢å¤§äº†ï¼‰
  # æœ‰æ•ˆ batch size = per_device_train_batch_size * gradient_accumulation_steps
  gradient_accumulation_steps: 2

  # é¢„çƒ­æ­¥æ•°
  warmup_steps: 10

  # æœ€å¤§è®­ç»ƒæ­¥æ•°
  max_steps: 60

  # è®­ç»ƒè½®æ•°ï¼ˆå¦‚æœè®¾ç½®æ­¤é¡¹ï¼Œmax_steps ä¼šè¢«å¿½ç•¥ï¼‰
  # num_train_epochs: 1

  # å­¦ä¹ ç‡ - é€‚å½“æé«˜ä»¥åŠ å¿«æ”¶æ•›
  learning_rate: 3e-4

  # æ—¥å¿—è®°å½•æ­¥æ•°
  logging_steps: 1

  # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨ adamw_8bit èŠ‚çœå†…å­˜ï¼Œæˆ–ä½¿ç”¨ adamw_torch_fused è·å¾—æœ€ä½³æ€§èƒ½
  optim: "adamw_torch_fused"

  # æƒé‡è¡°å‡
  weight_decay: 0.01

  # å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹ - cosine é€šå¸¸è¡¨ç°æ›´å¥½
  lr_scheduler_type: "cosine"

  # éšæœºç§å­
  seed: 3407

  # ğŸš€ ä¼˜åŒ–ï¼šå¤§å¹…å¢åŠ æ•°æ®åŠ è½½å™¨å·¥ä½œçº¿ç¨‹æ•°
  # å»ºè®®è®¾ç½®ä¸º CPU æ ¸å¿ƒæ•°çš„ 1/4 åˆ° 1/2
  dataloader_num_workers: 8

  # ğŸš€ ä¼˜åŒ–ï¼šå¯ç”¨æ•°æ®é¢„å–ä»¥å‡å°‘ I/O ç­‰å¾…
  # æ¯ä¸ª worker é¢„å–çš„ batch æ•°é‡
  dataloader_prefetch_factor: 4

  # ğŸš€ ä¼˜åŒ–ï¼šå¯ç”¨ pin_memory åŠ é€Ÿ CPU åˆ° GPU æ•°æ®ä¼ è¾“
  dataloader_pin_memory: true

  # ğŸš€ ä¼˜åŒ–ï¼šå¯ç”¨æŒä¹…åŒ– workersï¼Œé¿å…é‡å¤åˆ›å»ºè¿›ç¨‹
  dataloader_persistent_workers: true

  # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨æ›´é«˜æ•ˆçš„ä¿å­˜ç­–ç•¥
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 2

  # ğŸš€ ä¼˜åŒ–ï¼šå¯ç”¨æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
  max_grad_norm: 1.0

  # æŠ¥å‘Šå·¥å…·ï¼ˆå¯é€‰ï¼štensorboard, wandbï¼‰
  report_to: "none"

  # ğŸš€ ä¼˜åŒ–ï¼šè®¾ç½®æœ€ä½³ dtype ç­–ç•¥
  # A100 åŸç”Ÿæ”¯æŒ bf16ï¼Œæ€§èƒ½æœ€ä½³
  bf16: true
  fp16: false

  # ğŸš€ ä¼˜åŒ–ï¼šå¯ç”¨ TF32 ä»¥åŠ é€ŸçŸ©é˜µè¿ç®—ï¼ˆA100 æ”¯æŒï¼‰
  tf32: true

  # ğŸš€ ä¼˜åŒ–ï¼šå¯ç”¨ç¼–è¯‘ä¼˜åŒ–ï¼ˆPyTorch 2.0+ï¼‰
  # torch_compile: true
  # torch_compile_backend: "inductor"
  # torch_compile_mode: "default"

# æ¨¡å‹ä¿å­˜é…ç½®
saving:
  # LoRA æ¨¡å‹ä¿å­˜è·¯å¾„
  lora_model_path: "lora_model"

  # æ˜¯å¦ä¿å­˜åˆå¹¶åçš„å®Œæ•´æ¨¡å‹
  save_merged_model: false

  # åˆå¹¶åçš„æ¨¡å‹ä¿å­˜è·¯å¾„
  merged_model_path: "merged_model"
