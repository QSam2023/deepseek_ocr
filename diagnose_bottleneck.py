#!/usr/bin/env python3
"""
æ€§èƒ½ç“¶é¢ˆè¯Šæ–­å·¥å…·
åˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­çš„å„ä¸ªç¯èŠ‚ï¼Œæ‰¾å‡ºçœŸæ­£çš„æ€§èƒ½ç“¶é¢ˆ
"""

import os
import sys
import time
import json
import yaml
import torch
import argparse
from pathlib import Path
from typing import Dict, List, Any
from PIL import Image
import numpy as np


class Color:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'


def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{Color.HEADER}{'=' * 80}")
    print(f"{title}")
    print(f"{'=' * 80}{Color.ENDC}\n")


def benchmark_data_loading(config_path: str, num_samples: int = 100):
    """åŸºå‡†æµ‹è¯•æ•°æ®åŠ è½½é€Ÿåº¦"""
    print_section("1ï¸âƒ£  æ•°æ®åŠ è½½æ€§èƒ½æµ‹è¯•")

    # åŠ è½½é…ç½®
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # åŠ è½½è®­ç»ƒæ•°æ®
    split_data_dir = config['data']['split_data_dir']
    data_type = config['data']['data_type']

    train_files = []
    if data_type == 'all':
        train_files = ['table_ocr_train.json', 'stamp_ocr_train.json', 'stamp_cls_train.json']
    elif data_type == 'table':
        train_files = ['table_ocr_train.json']
    elif data_type == 'stamp':
        train_files = ['stamp_ocr_train.json', 'stamp_cls_train.json']

    all_train_data = []
    for train_file in train_files:
        file_path = os.path.join(split_data_dir, train_file)
        if os.path.exists(file_path):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            all_train_data.extend(data)

    if not all_train_data:
        print(f"{Color.FAIL}é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒæ•°æ®{Color.ENDC}")
        return {}

    print(f"æ€»æ•°æ®é‡: {len(all_train_data)} æ ·æœ¬")
    print(f"æµ‹è¯•æ ·æœ¬æ•°: {min(num_samples, len(all_train_data))} æ ·æœ¬\n")

    # æµ‹è¯•çº¯æ•°æ®è¯»å–ï¼ˆä¸åŒ…å«å›¾åƒï¼‰
    print(f"{Color.OKCYAN}æµ‹è¯• 1: JSON æ•°æ®è¯»å–{Color.ENDC}")
    start_time = time.time()
    for i in range(min(num_samples, len(all_train_data))):
        sample = all_train_data[i]
        _ = sample.get('image_path')
        _ = sample.get('prompt')
        _ = sample.get('result')
    json_time = time.time() - start_time
    print(f"  è€—æ—¶: {json_time:.3f} ç§’")
    print(f"  é€Ÿåº¦: {min(num_samples, len(all_train_data)) / json_time:.1f} æ ·æœ¬/ç§’")

    # æµ‹è¯•å›¾åƒåŠ è½½
    print(f"\n{Color.OKCYAN}æµ‹è¯• 2: å›¾åƒæ–‡ä»¶åŠ è½½{Color.ENDC}")
    image_load_times = []
    image_sizes = []

    for i in range(min(num_samples, len(all_train_data))):
        sample = all_train_data[i]
        image_path = sample.get('image_path')
        if image_path and os.path.exists(image_path):
            start = time.time()
            img = Image.open(image_path).convert('RGB')
            image_load_times.append(time.time() - start)
            image_sizes.append(img.size)

    if image_load_times:
        avg_load_time = np.mean(image_load_times)
        total_load_time = sum(image_load_times)
        print(f"  å¹³å‡å›¾åƒåŠ è½½æ—¶é—´: {avg_load_time*1000:.2f} ms")
        print(f"  æ€»è€—æ—¶: {total_load_time:.3f} ç§’")
        print(f"  é€Ÿåº¦: {len(image_load_times) / total_load_time:.1f} å›¾åƒ/ç§’")
        print(f"  å¹³å‡å›¾åƒå°ºå¯¸: {int(np.mean([s[0] for s in image_sizes]))}x{int(np.mean([s[1] for s in image_sizes]))}")

    # æµ‹è¯•å›¾åƒé¢„å¤„ç†
    print(f"\n{Color.OKCYAN}æµ‹è¯• 3: å›¾åƒé¢„å¤„ç†ï¼ˆresize + tensorï¼‰{Color.ENDC}")
    from data_collator import DeepSeekOCRDataCollator

    base_size = config['data_processing']['base_size']
    preprocess_times = []

    for i in range(min(20, len(all_train_data))):  # åªæµ‹è¯•20ä¸ªæ ·æœ¬
        sample = all_train_data[i]
        image_path = sample.get('image_path')
        if image_path and os.path.exists(image_path):
            img = Image.open(image_path).convert('RGB')

            start = time.time()
            # æ¨¡æ‹Ÿé¢„å¤„ç†
            from PIL import ImageOps
            global_view = ImageOps.pad(img, (base_size, base_size))
            _ = torch.tensor(np.array(global_view)).permute(2, 0, 1).float()
            preprocess_times.append(time.time() - start)

    if preprocess_times:
        avg_preprocess = np.mean(preprocess_times)
        print(f"  å¹³å‡é¢„å¤„ç†æ—¶é—´: {avg_preprocess*1000:.2f} ms")
        print(f"  é¢„ä¼°é€Ÿåº¦: {1/avg_preprocess:.1f} æ ·æœ¬/ç§’")

    return {
        'json_read_speed': min(num_samples, len(all_train_data)) / json_time if json_time > 0 else 0,
        'image_load_time_ms': np.mean(image_load_times) * 1000 if image_load_times else 0,
        'image_load_speed': len(image_load_times) / sum(image_load_times) if image_load_times else 0,
        'preprocess_time_ms': np.mean(preprocess_times) * 1000 if preprocess_times else 0,
        'total_data_pipeline_time_ms': (
            (np.mean(image_load_times) + np.mean(preprocess_times)) * 1000
            if image_load_times and preprocess_times else 0
        )
    }


def benchmark_model_forward(config_path: str):
    """åŸºå‡†æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­é€Ÿåº¦"""
    print_section("2ï¸âƒ£  æ¨¡å‹è®¡ç®—æ€§èƒ½æµ‹è¯•")

    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    try:
        from unsloth import FastVisionModel
        from transformers import AutoModel

        print("åŠ è½½æ¨¡å‹...")
        os.environ["UNSLOTH_WARN_UNINITIALIZED"] = '0'

        model_path = config['model']['model_path']

        model, tokenizer = FastVisionModel.from_pretrained(
            model_path,
            load_in_4bit=config['model']['load_in_4bit'],
            auto_model=AutoModel,
            trust_remote_code=True,
            unsloth_force_compile=config['model']['unsloth_force_compile'],
            use_gradient_checkpointing=config['model']['use_gradient_checkpointing'],
        )

        # é…ç½® LoRA
        lora_config = config['model']['lora']
        model = FastVisionModel.get_peft_model(
            model,
            target_modules=lora_config['target_modules'],
            r=int(lora_config['r']),
            lora_alpha=int(lora_config['lora_alpha']),
            lora_dropout=float(lora_config['lora_dropout']),
            bias=str(lora_config['bias']),
            random_state=int(lora_config['random_state']),
            use_rslora=bool(lora_config['use_rslora']),
        )

        FastVisionModel.for_training(model)
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ\n")

        # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
        batch_size = config['training']['per_device_train_batch_size']
        seq_length = 512  # æ¨¡æ‹Ÿåºåˆ—é•¿åº¦

        print(f"{Color.OKCYAN}æµ‹è¯•é…ç½®:{Color.ENDC}")
        print(f"  Batch Size: {batch_size}")
        print(f"  Sequence Length: {seq_length}")
        print(f"  LoRA Rank: {lora_config['r']}")

        # åˆ›å»ºæ¨¡æ‹Ÿè¾“å…¥
        input_ids = torch.randint(0, 32000, (batch_size, seq_length)).cuda()
        attention_mask = torch.ones(batch_size, seq_length).cuda()

        # é¢„çƒ­
        print(f"\n{Color.OKCYAN}é¢„çƒ­ä¸­...{Color.ENDC}")
        with torch.no_grad():
            for _ in range(3):
                _ = model(input_ids=input_ids, attention_mask=attention_mask)

        if torch.cuda.is_available():
            torch.cuda.synchronize()

        # æµ‹è¯•å‰å‘ä¼ æ’­
        print(f"\n{Color.OKCYAN}æµ‹è¯•: å‰å‘ä¼ æ’­{Color.ENDC}")
        forward_times = []
        for _ in range(10):
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            start = time.time()

            with torch.no_grad():
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)

            if torch.cuda.is_available():
                torch.cuda.synchronize()
            forward_times.append(time.time() - start)

        avg_forward = np.mean(forward_times)
        print(f"  å¹³å‡å‰å‘æ—¶é—´: {avg_forward*1000:.2f} ms")
        print(f"  ååé‡: {batch_size / avg_forward:.1f} æ ·æœ¬/ç§’")

        # æµ‹è¯•å‰å‘+åå‘ä¼ æ’­
        print(f"\n{Color.OKCYAN}æµ‹è¯•: å‰å‘+åå‘ä¼ æ’­{Color.ENDC}")
        model.train()
        backward_times = []

        for _ in range(10):
            if torch.cuda.is_available():
                torch.cuda.synchronize()
            start = time.time()

            outputs = model(input_ids=input_ids, attention_mask=attention_mask)
            loss = outputs.logits.mean()  # æ¨¡æ‹ŸæŸå¤±
            loss.backward()

            if torch.cuda.is_available():
                torch.cuda.synchronize()
            backward_times.append(time.time() - start)

            # æ¸…é™¤æ¢¯åº¦
            model.zero_grad()

        avg_backward = np.mean(backward_times)
        print(f"  å¹³å‡å‰å‘+åå‘æ—¶é—´: {avg_backward*1000:.2f} ms")
        print(f"  ååé‡: {batch_size / avg_backward:.1f} æ ·æœ¬/ç§’")

        return {
            'forward_time_ms': avg_forward * 1000,
            'backward_time_ms': avg_backward * 1000,
            'throughput_samples_per_sec': batch_size / avg_backward
        }

    except Exception as e:
        print(f"{Color.FAIL}æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}{Color.ENDC}")
        import traceback
        traceback.print_exc()
        return {}


def analyze_bottleneck(data_stats: Dict, model_stats: Dict):
    """åˆ†æç“¶é¢ˆ"""
    print_section("3ï¸âƒ£  ç“¶é¢ˆåˆ†æ")

    if not data_stats or not model_stats:
        print(f"{Color.WARNING}æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•åˆ†æ{Color.ENDC}")
        return

    data_time = data_stats.get('total_data_pipeline_time_ms', 0)
    model_time = model_stats.get('backward_time_ms', 0)

    print(f"{Color.BOLD}æ—¶é—´åˆ†è§£:{Color.ENDC}")
    print(f"  æ•°æ®åŠ è½½+é¢„å¤„ç†: {data_time:.2f} ms")
    print(f"  æ¨¡å‹å‰å‘+åå‘:   {model_time:.2f} ms")
    print(f"  æ€»æ—¶é—´ (ç†è®º):   {data_time + model_time:.2f} ms\n")

    total_time = data_time + model_time
    data_percent = (data_time / total_time * 100) if total_time > 0 else 0
    model_percent = (model_time / total_time * 100) if total_time > 0 else 0

    print(f"{Color.BOLD}æ—¶é—´å æ¯”:{Color.ENDC}")
    print(f"  æ•°æ®å¤„ç†: {data_percent:.1f}%")
    print(f"  æ¨¡å‹è®¡ç®—: {model_percent:.1f}%\n")

    print(f"{Color.BOLD}ç“¶é¢ˆè¯Šæ–­:{Color.ENDC}")

    if data_percent > 40:
        print(f"  {Color.FAIL}ğŸ”´ æ•°æ®åŠ è½½æ˜¯ä¸»è¦ç“¶é¢ˆ ({data_percent:.1f}%){Color.ENDC}")
        print(f"\n{Color.OKCYAN}å»ºè®®ä¼˜åŒ–:{Color.ENDC}")
        print("  1. å¢åŠ  dataloader_num_workers")
        print("  2. å¯ç”¨ dataloader_prefetch_factor")
        print("  3. ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨ï¼ˆSSD/NVMeï¼‰")
        print("  4. é¢„å¤„ç†å¹¶ç¼“å­˜å›¾åƒ")
    elif model_percent > 60:
        print(f"  {Color.OKGREEN}ğŸŸ¢ æ¨¡å‹è®¡ç®—æ˜¯ä¸»è¦éƒ¨åˆ† ({model_percent:.1f}%) - è¿™æ˜¯æ­£å¸¸çš„{Color.ENDC}")
        print(f"\n{Color.OKCYAN}è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:{Color.ENDC}")
        print("  1. å¢åŠ  batch sizeï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰")
        print("  2. ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆbf16/fp16ï¼‰")
        print("  3. å¯ç”¨ torch.compileï¼ˆPyTorch 2.0+ï¼‰")
        print("  4. è€ƒè™‘å‡å°æ¨¡å‹å¤§å°æˆ–åºåˆ—é•¿åº¦")
    else:
        print(f"  {Color.OKCYAN}ğŸŸ¡ æ•°æ®å’Œè®¡ç®—è¾ƒä¸ºå¹³è¡¡{Color.ENDC}")
        print(f"\n{Color.OKCYAN}ä¼˜åŒ–å»ºè®®:{Color.ENDC}")
        print("  1. åŒæ—¶ä¼˜åŒ–æ•°æ®åŠ è½½å’Œæ¨¡å‹è®¡ç®—")
        print("  2. å¢åŠ  batch size")
        print("  3. æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–éšè—ç“¶é¢ˆ")


def check_gpu_utilization():
    """æ£€æŸ¥ GPU åˆ©ç”¨ç‡"""
    print_section("4ï¸âƒ£  GPU åˆ©ç”¨ç‡æ£€æŸ¥")

    try:
        import subprocess
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=name,utilization.gpu,utilization.memory,memory.used,memory.total',
             '--format=csv,noheader,nounits'],
            capture_output=True,
            text=True,
            check=True
        )

        parts = result.stdout.strip().split(', ')
        gpu_name = parts[0]
        gpu_util = float(parts[1])
        mem_util = float(parts[2])
        mem_used = float(parts[3])
        mem_total = float(parts[4])

        print(f"{Color.BOLD}å½“å‰ GPU çŠ¶æ€:{Color.ENDC}")
        print(f"  GPU: {gpu_name}")
        print(f"  è®¡ç®—åˆ©ç”¨ç‡: {gpu_util}%")
        print(f"  æ˜¾å­˜åˆ©ç”¨ç‡: {mem_util}%")
        print(f"  æ˜¾å­˜ä½¿ç”¨: {mem_used}MB / {mem_total}MB\n")

        print(f"{Color.BOLD}åˆ©ç”¨ç‡è¯„ä¼°:{Color.ENDC}")
        if gpu_util < 30:
            print(f"  {Color.FAIL}ğŸ”´ GPU åˆ©ç”¨ç‡æä½ ({gpu_util}%){Color.ENDC}")
            print("  å¯èƒ½åŸå› : æ•°æ®åŠ è½½ç“¶é¢ˆã€batch size å¤ªå°")
        elif gpu_util < 50:
            print(f"  {Color.WARNING}ğŸŸ¡ GPU åˆ©ç”¨ç‡åä½ ({gpu_util}%){Color.ENDC}")
            print("  æœ‰ä¼˜åŒ–ç©ºé—´")
        elif gpu_util < 70:
            print(f"  {Color.OKCYAN}ğŸŸ¢ GPU åˆ©ç”¨ç‡ä¸­ç­‰ ({gpu_util}%){Color.ENDC}")
            print("  è¾ƒä¸ºåˆç†")
        else:
            print(f"  {Color.OKGREEN}ğŸŸ¢ GPU åˆ©ç”¨ç‡è‰¯å¥½ ({gpu_util}%){Color.ENDC}")
            print("  å·²å……åˆ†åˆ©ç”¨")

        if mem_used / mem_total < 0.3:
            print(f"\n  {Color.WARNING}âš ï¸  æ˜¾å­˜åˆ©ç”¨ç‡ä½ ({mem_used/mem_total*100:.1f}%){Color.ENDC}")
            print("  å»ºè®®: å¯ä»¥å¢å¤§ batch size æˆ–æ¨¡å‹ rank")

    except Exception as e:
        print(f"{Color.WARNING}æ— æ³•è·å– GPU ä¿¡æ¯: {e}{Color.ENDC}")


def main():
    parser = argparse.ArgumentParser(
        description="æ€§èƒ½ç“¶é¢ˆæ·±åº¦è¯Šæ–­å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    parser.add_argument('--config', type=str, default='train_config_optimized.yaml',
                        help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--num-samples', type=int, default=100,
                        help='æµ‹è¯•æ ·æœ¬æ•°é‡')
    parser.add_argument('--skip-model', action='store_true',
                        help='è·³è¿‡æ¨¡å‹æµ‹è¯•ï¼ˆåŠ å¿«è¯Šæ–­ï¼‰')

    args = parser.parse_args()

    print_section("ğŸ” DeepSeek OCR æ€§èƒ½ç“¶é¢ˆè¯Šæ–­")

    # æ£€æŸ¥ GPU
    check_gpu_utilization()

    # æµ‹è¯•æ•°æ®åŠ è½½
    data_stats = benchmark_data_loading(args.config, args.num_samples)

    # æµ‹è¯•æ¨¡å‹è®¡ç®—
    model_stats = {}
    if not args.skip_model:
        model_stats = benchmark_model_forward(args.config)

    # åˆ†æç“¶é¢ˆ
    if data_stats and model_stats:
        analyze_bottleneck(data_stats, model_stats)

    print_section("âœ… è¯Šæ–­å®Œæˆ")
    print(f"{Color.OKBLUE}å»ºè®®: æ ¹æ®ä¸Šè¿°åˆ†æç»“æœè°ƒæ•´é…ç½®{Color.ENDC}\n")


if __name__ == "__main__":
    main()
