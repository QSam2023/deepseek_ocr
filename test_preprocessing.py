#!/usr/bin/env python3
"""
æµ‹è¯•å›¾ç‰‡é¢„å¤„ç†å’Œç¼“å­˜åŠŸèƒ½
éªŒè¯é¢„å¤„ç†æ˜¯å¦æ­£ç¡®å·¥ä½œï¼Œä»¥åŠæ€§èƒ½æå‡æ•ˆæœ
"""

import os
import sys
import time
import json
import argparse
from pathlib import Path


def test_single_image_preprocessing(image_path: str, task_type: str = "table_ocr"):
    """æµ‹è¯•å•å¼ å›¾ç‰‡çš„é¢„å¤„ç†"""
    from image_preprocessor import ImagePreprocessor

    print("\n" + "=" * 80)
    print("ğŸ§ª æµ‹è¯• 1: å•å¼ å›¾ç‰‡é¢„å¤„ç†")
    print("=" * 80)

    preprocessor = ImagePreprocessor(
        image_size=640,
        base_size=1024,
        crop_mode=True,
        cache_dir="ocr_data/preprocessed_cache"
    )

    print(f"å›¾ç‰‡è·¯å¾„: {image_path}")
    print(f"ä»»åŠ¡ç±»å‹: {task_type}")

    # é¢„å¤„ç†
    print("\nâ³ é¢„å¤„ç†å›¾ç‰‡...")
    start = time.time()
    preprocessed = preprocessor.preprocess_image(image_path)
    preprocess_time = time.time() - start

    print(f"âœ“ é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶: {preprocess_time:.3f} ç§’")
    print(f"\né¢„å¤„ç†ç»“æœ:")
    print(f"  - images_ori shape: {preprocessed['images_ori'].shape}")
    print(f"  - images_crop shape: {preprocessed['images_crop'].shape}")
    print(f"  - images_spatial_crop shape: {preprocessed['images_spatial_crop'].shape}")
    print(f"  - tokenized_image length: {len(preprocessed['tokenized_image'])}")
    print(f"  - crop_ratio: {preprocessed['crop_ratio']}")
    print(f"  - original_size: {preprocessed['original_size']}")

    # ä¿å­˜ç¼“å­˜
    cache_path = preprocessor.get_cache_path(image_path, task_type)
    print(f"\nâ³ ä¿å­˜ç¼“å­˜åˆ°: {cache_path}")
    start = time.time()
    preprocessor.save_cache(preprocessed, cache_path)
    save_time = time.time() - start
    print(f"âœ“ ç¼“å­˜ä¿å­˜å®Œæˆï¼Œè€—æ—¶: {save_time:.3f} ç§’")

    # åŠ è½½ç¼“å­˜
    print(f"\nâ³ ä»ç¼“å­˜åŠ è½½...")
    start = time.time()
    loaded = preprocessor.load_cache(cache_path)
    load_time = time.time() - start
    print(f"âœ“ ç¼“å­˜åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.3f} ç§’")

    # éªŒè¯
    print(f"\nâœ… éªŒè¯ç¼“å­˜:")
    print(f"  - æ•°æ®å®Œæ•´æ€§: {'é€šè¿‡' if loaded is not None else 'å¤±è´¥'}")
    print(f"  - åŠ è½½é€Ÿåº¦æå‡: {preprocess_time / load_time:.1f}x")

    return cache_path, preprocess_time, load_time


def test_batch_preprocessing():
    """æµ‹è¯•æ‰¹é‡é¢„å¤„ç†"""
    print("\n" + "=" * 80)
    print("ğŸ§ª æµ‹è¯• 2: æ‰¹é‡é¢„å¤„ç†")
    print("=" * 80)

    # æŸ¥æ‰¾æµ‹è¯•æ•°æ®
    test_json = "ocr_data/splited_data/table_ocr_test.json"
    if not os.path.exists(test_json):
        print(f"âš ï¸  è·³è¿‡ï¼šæµ‹è¯•æ•°æ®ä¸å­˜åœ¨ {test_json}")
        return

    with open(test_json, 'r', encoding='utf-8') as f:
        test_data = json.load(f)

    # å–å‰ 10 å¼ å›¾ç‰‡æµ‹è¯•
    test_samples = test_data[:min(10, len(test_data))]
    image_paths = [item['image_path'] for item in test_samples]
    task_types = [item['task_type'] for item in test_samples]

    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_samples)}")

    from image_preprocessor import batch_preprocess_images

    print("\nâ³ æ‰¹é‡é¢„å¤„ç†...")
    start = time.time()
    cache_paths = batch_preprocess_images(
        image_paths=image_paths,
        task_types=task_types,
        image_size=640,
        base_size=1024,
        crop_mode=True,
        cache_dir="ocr_data/preprocessed_cache",
        verbose=True
    )
    total_time = time.time() - start

    success_count = sum(1 for p in cache_paths if p is not None)
    print(f"\nâœ“ æ‰¹é‡é¢„å¤„ç†å®Œæˆ")
    print(f"  - æˆåŠŸ: {success_count}/{len(test_samples)}")
    print(f"  - æ€»è€—æ—¶: {total_time:.2f} ç§’")
    print(f"  - å¹³å‡è€—æ—¶: {total_time/len(test_samples):.3f} ç§’/å›¾")


def test_data_collator_with_cache():
    """æµ‹è¯• data collator åŠ è½½ç¼“å­˜"""
    print("\n" + "=" * 80)
    print("ğŸ§ª æµ‹è¯• 3: Data Collator åŠ è½½ç¼“å­˜")
    print("=" * 80)

    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_json = "ocr_data/splited_data/table_ocr_test.json"
    if not os.path.exists(test_json):
        print(f"âš ï¸  è·³è¿‡ï¼šæµ‹è¯•æ•°æ®ä¸å­˜åœ¨ {test_json}")
        return

    with open(test_json, 'r', encoding='utf-8') as f:
        test_data = json.load(f)

    if not test_data:
        print("âš ï¸  è·³è¿‡ï¼šæ²¡æœ‰æµ‹è¯•æ•°æ®")
        return

    # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
    sample = test_data[0]

    # æ£€æŸ¥æ˜¯å¦æœ‰é¢„å¤„ç†ç¼“å­˜
    if 'preprocessed_path' not in sample:
        print("âš ï¸  è·³è¿‡ï¼šæµ‹è¯•æ•°æ®æ²¡æœ‰é¢„å¤„ç†ç¼“å­˜ï¼Œè¯·å…ˆè¿è¡Œ:")
        print("     python split_ocr_data.py --data_type table --preprocess")
        return

    print(f"æ ·æœ¬å›¾ç‰‡: {sample['image_path']}")
    print(f"ç¼“å­˜è·¯å¾„: {sample.get('preprocessed_path', 'N/A')}")

    # æ¨¡æ‹Ÿ data collator çš„å¤„ç†
    try:
        from PIL import Image
        from unsloth_data_collator import DeepSeekOCRDataCollator

        # åˆ›å»ºç®€å•çš„ mock tokenizer å’Œ model
        class MockTokenizer:
            def __init__(self):
                self.bos_token_id = 1
                self.eos_token = "</s>"
                self.pad_token_id = 0

        class MockModel:
            def __init__(self):
                import torch
                self.dtype = torch.float16

        tokenizer = MockTokenizer()
        model = MockModel()

        collator = DeepSeekOCRDataCollator(
            tokenizer=tokenizer,
            model=model,
            image_size=640,
            base_size=1024,
            crop_mode=True
        )

        # å‡†å¤‡æ¶ˆæ¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        messages = [
            {
                "role": "<|User|>",
                "content": "<image>\nTest prompt",
                "images": [Image.open(sample['image_path'])]
            },
            {
                "role": "<|Assistant|>",
                "content": "Test response"
            }
        ]

        # æµ‹è¯•1: ä¸ä½¿ç”¨ç¼“å­˜
        print("\nâ³ æµ‹è¯•å®æ—¶å¤„ç†ï¼ˆä¸ä½¿ç”¨ç¼“å­˜ï¼‰...")
        start = time.time()
        result_no_cache = collator.process_single_sample(messages, preprocessed_path=None)
        time_no_cache = time.time() - start
        print(f"âœ“ å®Œæˆï¼Œè€—æ—¶: {time_no_cache:.3f} ç§’")

        # æµ‹è¯•2: ä½¿ç”¨ç¼“å­˜
        print("\nâ³ æµ‹è¯•ä»ç¼“å­˜åŠ è½½...")
        start = time.time()
        result_with_cache = collator.process_single_sample(messages, preprocessed_path=sample['preprocessed_path'])
        time_with_cache = time.time() - start
        print(f"âœ“ å®Œæˆï¼Œè€—æ—¶: {time_with_cache:.3f} ç§’")

        # å¯¹æ¯”
        print(f"\nğŸ“Š æ€§èƒ½å¯¹æ¯”:")
        print(f"  - å®æ—¶å¤„ç†: {time_no_cache:.3f} ç§’")
        print(f"  - ç¼“å­˜åŠ è½½: {time_with_cache:.3f} ç§’")
        print(f"  - é€Ÿåº¦æå‡: {time_no_cache / time_with_cache:.1f}x")

        # éªŒè¯ç»“æœä¸€è‡´æ€§
        print(f"\nâœ… ç»“æœéªŒè¯:")
        print(f"  - input_ids shape: {result_no_cache['input_ids'].shape} vs {result_with_cache['input_ids'].shape}")
        print(f"  - images_ori shape: {result_no_cache['images_ori'].shape} vs {result_with_cache['images_ori'].shape}")

    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    parser = argparse.ArgumentParser(description="æµ‹è¯•å›¾ç‰‡é¢„å¤„ç†å’Œç¼“å­˜åŠŸèƒ½")
    parser.add_argument(
        '--test_image',
        type=str,
        default=None,
        help='æµ‹è¯•å›¾ç‰‡è·¯å¾„'
    )
    parser.add_argument(
        '--all',
        action='store_true',
        help='è¿è¡Œæ‰€æœ‰æµ‹è¯•'
    )

    args = parser.parse_args()

    print("=" * 80)
    print("ğŸš€ å›¾ç‰‡é¢„å¤„ç†å’Œç¼“å­˜åŠŸèƒ½æµ‹è¯•")
    print("=" * 80)

    # æŸ¥æ‰¾æµ‹è¯•å›¾ç‰‡
    if args.test_image is None:
        test_json = "ocr_data/splited_data/table_ocr_test.json"
        if os.path.exists(test_json):
            with open(test_json, 'r', encoding='utf-8') as f:
                test_data = json.load(f)
                if test_data:
                    args.test_image = test_data[0]['image_path']
                    print(f"âœ“ è‡ªåŠ¨é€‰æ‹©æµ‹è¯•å›¾ç‰‡: {args.test_image}")

    if args.test_image and os.path.exists(args.test_image):
        # æµ‹è¯• 1: å•å¼ å›¾ç‰‡
        test_single_image_preprocessing(args.test_image)
    else:
        print("\nâš ï¸  è·³è¿‡æµ‹è¯• 1: æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")

    if args.all:
        # æµ‹è¯• 2: æ‰¹é‡é¢„å¤„ç†
        test_batch_preprocessing()

        # æµ‹è¯• 3: Data collator
        test_data_collator_with_cache()

    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)
    print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("  1. æ•°æ®åˆ‡åˆ†æ—¶å¯ç”¨é¢„å¤„ç†:")
    print("     python split_ocr_data.py --data_type table --preprocess")
    print("\n  2. è®­ç»ƒæ—¶è‡ªåŠ¨ä½¿ç”¨ç¼“å­˜ï¼ˆæ— éœ€ä¿®æ”¹è®­ç»ƒå‘½ä»¤ï¼‰:")
    print("     python train_model.py --config train_config.yaml")
    print("\n  3. è·³è¿‡æ•°æ®åˆ‡åˆ†ï¼Œç›´æ¥ä½¿ç”¨å·²æœ‰ç¼“å­˜:")
    print("     python train_and_evaluate.py --skip_data_split")
    print()


if __name__ == "__main__":
    main()
