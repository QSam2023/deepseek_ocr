#!/usr/bin/env python3
"""
å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹è„šæœ¬
1. æ£€æŸ¥åŸºç¡€æ¨¡å‹
2. åˆ’åˆ†æ•°æ®é›†
3. è®­ç»ƒå‰è¯„ä¼°ï¼ˆä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼‰
4. è®­ç»ƒæ¨¡å‹
5. è®­ç»ƒåè¯„ä¼°ï¼ˆä½¿ç”¨ LoRA æ¨¡å‹ï¼‰
6. å¯¹æ¯”ç»“æœ
"""

import os
import sys
import json
import yaml
import time
import argparse
import subprocess
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional


class Color:
    """ç»ˆç«¯é¢œè‰²"""
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


def print_section(title: str, color: str = Color.HEADER):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{color}{'=' * 80}")
    print(f"{title}")
    print(f"{'=' * 80}{Color.ENDC}\n")


def print_step(step: str, total: int, current: int, description: str):
    """æ‰“å°æ­¥éª¤ä¿¡æ¯"""
    print(f"\n{Color.BOLD}{Color.OKCYAN}[æ­¥éª¤ {current}/{total}] {step}{Color.ENDC}")
    print(f"{Color.OKBLUE}{description}{Color.ENDC}")
    print("-" * 80)


def run_command(cmd: List[str], description: str, check: bool = True) -> bool:
    """
    è¿è¡Œå‘½ä»¤å¹¶å¤„ç†è¾“å‡º

    Args:
        cmd: å‘½ä»¤åˆ—è¡¨
        description: å‘½ä»¤æè¿°
        check: æ˜¯å¦æ£€æŸ¥è¿”å›ç 

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print(f"\n{Color.OKBLUE}è¿è¡Œ: {' '.join(cmd)}{Color.ENDC}\n")

    result = subprocess.run(cmd, capture_output=False)

    if check and result.returncode != 0:
        print(f"\n{Color.FAIL}âœ— é”™è¯¯: {description} å¤±è´¥ (è¿”å›ç : {result.returncode}){Color.ENDC}")
        return False

    print(f"\n{Color.OKGREEN}âœ“ {description} å®Œæˆ{Color.ENDC}")
    return True


def step_1_check_model(model_dir: str, model_id: str, auto_download: bool) -> bool:
    """æ­¥éª¤ 1: æ£€æŸ¥åŸºç¡€æ¨¡å‹"""
    print_step("æ£€æŸ¥åŸºç¡€æ¨¡å‹", 6, 1, f"æ£€æŸ¥æ¨¡å‹ç›®å½•: {model_dir}")

    cmd = [sys.executable, 'check_origin_model.py', '--model_dir', model_dir, '--model_id', model_id]

    if auto_download:
        cmd.append('--auto-download')

    return run_command(cmd, "æ¨¡å‹æ£€æŸ¥")


def step_2_split_data(data_type: str, data_root: str, output_dir: str,
                      train_ratio: float, seed: int) -> bool:
    """æ­¥éª¤ 2: åˆ’åˆ†æ•°æ®é›†"""
    print_step("åˆ’åˆ†æ•°æ®é›†", 6, 2, f"æ•°æ®ç±»å‹: {data_type}, è®­ç»ƒæ¯”ä¾‹: {train_ratio}")

    # ç¡®å®šè¦åˆ’åˆ†çš„æ•°æ®ç±»å‹
    types_to_split = []
    if data_type == 'all':
        types_to_split = ['table', 'stamp']
    elif data_type == 'table':
        types_to_split = ['table']
    elif data_type == 'stamp':
        types_to_split = ['stamp']

    # åˆ’åˆ†æ•°æ®
    for dtype in types_to_split:
        print(f"\n{Color.OKBLUE}åˆ’åˆ† {dtype} æ•°æ®...{Color.ENDC}")
        cmd = [
            sys.executable, 'split_ocr_data.py',
            '--data_type', dtype,
            '--data_root', data_root,
            '--output_dir', output_dir,
            '--train_ratio', str(train_ratio),
            '--seed', str(seed)
        ]

        if not run_command(cmd, f"åˆ’åˆ† {dtype} æ•°æ®"):
            return False

    return True


def step_3_baseline_inference(data_type: str, model_path: str, split_data_dir: str,
                               output_dir: str) -> bool:
    """æ­¥éª¤ 3: è®­ç»ƒå‰è¯„ä¼°ï¼ˆåŸºçº¿ï¼‰"""
    print_step("è®­ç»ƒå‰è¯„ä¼°", 6, 3, f"ä½¿ç”¨åŸºç¡€æ¨¡å‹: {model_path}")

    cmd = [
        sys.executable, 'batch_inference.py',
        '--data_type', data_type,
        '--inference_mode', 'local',
        '--model_path', model_path,
        '--split_data_dir', split_data_dir,
        '--output_dir', output_dir,
        '--no-resume'  # ä»å¤´å¼€å§‹
    ]

    return run_command(cmd, "è®­ç»ƒå‰æ¨ç†")


def step_4_train_model(config_path: str, overrides: Dict[str, Any]) -> bool:
    """æ­¥éª¤ 4: è®­ç»ƒæ¨¡å‹"""
    print_step("è®­ç»ƒæ¨¡å‹", 6, 4, f"é…ç½®æ–‡ä»¶: {config_path}")

    cmd = [sys.executable, 'train_model.py', '--config', config_path]

    # æ·»åŠ è¦†ç›–å‚æ•°
    if 'data_type' in overrides:
        cmd.extend(['--data_type', overrides['data_type']])
    if 'max_steps' in overrides:
        cmd.extend(['--max_steps', str(overrides['max_steps'])])
    if 'num_train_epochs' in overrides:
        cmd.extend(['--num_train_epochs', str(overrides['num_train_epochs'])])
    if 'learning_rate' in overrides:
        cmd.extend(['--learning_rate', str(overrides['learning_rate'])])
    if 'output_dir' in overrides:
        cmd.extend(['--output_dir', overrides['output_dir']])

    return run_command(cmd, "æ¨¡å‹è®­ç»ƒ")


def step_5_lora_inference(data_type: str, lora_path: str, base_model_path: str,
                          split_data_dir: str, output_dir: str) -> bool:
    """æ­¥éª¤ 5: è®­ç»ƒåè¯„ä¼°ï¼ˆLoRAï¼‰"""
    print_step("è®­ç»ƒåè¯„ä¼°", 6, 5, f"ä½¿ç”¨ LoRA æ¨¡å‹: {lora_path}")

    cmd = [
        sys.executable, 'batch_inference.py',
        '--data_type', data_type,
        '--inference_mode', 'local',
        '--model_path', lora_path,
        '--base_model_path', base_model_path,
        '--split_data_dir', split_data_dir,
        '--output_dir', output_dir,
        '--no-resume'  # ä»å¤´å¼€å§‹
    ]

    return run_command(cmd, "è®­ç»ƒåæ¨ç†")


def step_6_evaluate_and_compare(data_type: str, split_data_dir: str,
                                 baseline_dir: str, lora_dir: str) -> Dict[str, Any]:
    """æ­¥éª¤ 6: è¯„ä¼°å¹¶å¯¹æ¯”ç»“æœ"""
    print_step("è¯„ä¼°å¹¶å¯¹æ¯”ç»“æœ", 6, 6, "è¿è¡Œè¯„ä¼°è„šæœ¬å¹¶å¯¹æ¯”æ€§èƒ½")

    # ç¡®å®šè¦è¯„ä¼°çš„ä»»åŠ¡
    if data_type == 'all':
        tasks = [
            ('table_ocr', 'table_ocr_eval/eval_table_ocr.py'),
            ('stamp_ocr', 'stamp_ocr_eval/eval_stamp_ocr.py'),
            ('stamp_cls', 'stamp_cls_eval/eval_stamp_cls.py')
        ]
    elif data_type == 'table':
        tasks = [('table_ocr', 'table_ocr_eval/eval_table_ocr.py')]
    else:  # stamp
        tasks = [
            ('stamp_ocr', 'stamp_ocr_eval/eval_stamp_ocr.py'),
            ('stamp_cls', 'stamp_cls_eval/eval_stamp_cls.py')
        ]

    results = {}

    for task_type, eval_script in tasks:
        print(f"\n{Color.OKBLUE}{'=' * 80}")
        print(f"è¯„ä¼°ä»»åŠ¡: {task_type}")
        print(f"{'=' * 80}{Color.ENDC}\n")

        gt_file = os.path.join(split_data_dir, f"{task_type}_test.json")

        if not os.path.exists(gt_file):
            print(f"{Color.WARNING}âš  è·³è¿‡ {task_type}: æµ‹è¯•é›†æ–‡ä»¶ä¸å­˜åœ¨{Color.ENDC}")
            continue

        # è¯„ä¼°åŸºçº¿æ¨¡å‹
        print(f"\n{Color.OKCYAN}è¯„ä¼°åŸºçº¿æ¨¡å‹ (è®­ç»ƒå‰):{Color.ENDC}")
        baseline_pred_file = os.path.join(baseline_dir, "test", task_type, f"{task_type}_predictions.json")

        if os.path.exists(baseline_pred_file):
            cmd = [sys.executable, eval_script, gt_file, baseline_pred_file]
            run_command(cmd, f"åŸºçº¿æ¨¡å‹è¯„ä¼° ({task_type})", check=False)
        else:
            print(f"{Color.WARNING}âš  åŸºçº¿é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {baseline_pred_file}{Color.ENDC}")

        # è¯„ä¼° LoRA æ¨¡å‹
        print(f"\n{Color.OKCYAN}è¯„ä¼° LoRA æ¨¡å‹ (è®­ç»ƒå):{Color.ENDC}")
        lora_pred_file = os.path.join(lora_dir, "test", task_type, f"{task_type}_predictions.json")

        if os.path.exists(lora_pred_file):
            cmd = [sys.executable, eval_script, gt_file, lora_pred_file]
            run_command(cmd, f"LoRA æ¨¡å‹è¯„ä¼° ({task_type})", check=False)
        else:
            print(f"{Color.WARNING}âš  LoRA é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {lora_pred_file}{Color.ENDC}")

        results[task_type] = {
            'baseline_pred': baseline_pred_file,
            'lora_pred': lora_pred_file,
            'gt': gt_file
        }

    return results


def save_experiment_summary(config: Dict[str, Any], results: Dict[str, Any],
                            start_time: float, output_file: str):
    """ä¿å­˜å®éªŒæ€»ç»“"""
    summary = {
        'experiment_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'duration_seconds': time.time() - start_time,
        'config': config,
        'results': results,
    }

    os.makedirs(os.path.dirname(output_file) if os.path.dirname(output_file) else '.', exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print(f"\n{Color.OKGREEN}å®éªŒæ€»ç»“å·²ä¿å­˜: {output_file}{Color.ENDC}")


def main():
    parser = argparse.ArgumentParser(
        description="å®Œæ•´çš„è®­ç»ƒå’Œè¯„ä¼°æµç¨‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å·¥ä½œæµç¨‹:
  1. æ£€æŸ¥åŸºç¡€æ¨¡å‹ï¼ˆå¯è‡ªåŠ¨ä¸‹è½½ï¼‰
  2. åˆ’åˆ†æ•°æ®é›†
  3. è®­ç»ƒå‰è¯„ä¼°ï¼ˆä½¿ç”¨åŸºç¡€æ¨¡å‹ï¼‰
  4. è®­ç»ƒæ¨¡å‹
  5. è®­ç»ƒåè¯„ä¼°ï¼ˆä½¿ç”¨ LoRA æ¨¡å‹ï¼‰
  6. å¯¹æ¯”ç»“æœ

ç¤ºä¾‹ç”¨æ³•:
  # å®Œæ•´æµç¨‹ï¼ˆé»˜è®¤å‚æ•°ï¼‰
  python train_and_evaluate.py

  # è‡ªå®šä¹‰æ•°æ®ç±»å‹å’Œè®­ç»ƒæ­¥æ•°
  python train_and_evaluate.py --data_type stamp --max_steps 100

  # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
  python train_and_evaluate.py --train_config my_config.yaml

  # è·³è¿‡æŸäº›æ­¥éª¤
  python train_and_evaluate.py --skip_model_check --skip_data_split

  # è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼ˆæ— éœ€ç¡®è®¤ï¼‰
  python train_and_evaluate.py --auto_download_model

è¾“å‡ºç›®å½•:
  baseline_result/         - è®­ç»ƒå‰æ¨ç†ç»“æœ
  lora_result/             - è®­ç»ƒåæ¨ç†ç»“æœ
  lora_model/              - è®­ç»ƒçš„ LoRA æ¨¡å‹
  experiment_summary.json  - å®éªŒæ€»ç»“
        """
    )

    # åŸºç¡€é…ç½®
    parser.add_argument('--model_dir', type=str, default='./deepseek_ocr',
                        help='åŸºç¡€æ¨¡å‹ç›®å½• (é»˜è®¤: ./deepseek_ocr)')
    parser.add_argument('--model_id', type=str, default='unsloth/DeepSeek-OCR',
                        help='Hugging Face æ¨¡å‹ID (é»˜è®¤: unsloth/DeepSeek-OCR)')
    parser.add_argument('--auto_download_model', action='store_true',
                        help='è‡ªåŠ¨ä¸‹è½½æ¨¡å‹ï¼Œæ— éœ€ç¡®è®¤')

    # æ•°æ®é…ç½®
    parser.add_argument('--data_type', type=str, choices=['all', 'table', 'stamp'], default='all',
                        help='æ•°æ®ç±»å‹ (é»˜è®¤: all)')
    parser.add_argument('--data_root', type=str, default='ocr_data',
                        help='æ•°æ®æ ¹ç›®å½• (é»˜è®¤: ocr_data)')
    parser.add_argument('--split_data_dir', type=str, default='ocr_data/splited_data',
                        help='åˆ’åˆ†åçš„æ•°æ®ç›®å½• (é»˜è®¤: ocr_data/splited_data)')
    parser.add_argument('--train_ratio', type=float, default=0.8,
                        help='è®­ç»ƒé›†æ¯”ä¾‹ (é»˜è®¤: 0.8)')
    parser.add_argument('--split_seed', type=int, default=42,
                        help='æ•°æ®åˆ’åˆ†éšæœºç§å­ (é»˜è®¤: 42)')

    # è®­ç»ƒé…ç½®
    parser.add_argument('--train_config', type=str, default='train_config.yaml',
                        help='è®­ç»ƒé…ç½®æ–‡ä»¶ (é»˜è®¤: train_config.yaml)')
    parser.add_argument('--max_steps', type=int, default=None,
                        help='æœ€å¤§è®­ç»ƒæ­¥æ•° (è¦†ç›–é…ç½®æ–‡ä»¶)')
    parser.add_argument('--num_train_epochs', type=int, default=None,
                        help='è®­ç»ƒè½®æ•° (è¦†ç›–é…ç½®æ–‡ä»¶)')
    parser.add_argument('--learning_rate', type=float, default=None,
                        help='å­¦ä¹ ç‡ (è¦†ç›–é…ç½®æ–‡ä»¶)')
    parser.add_argument('--train_output_dir', type=str, default='outputs',
                        help='è®­ç»ƒè¾“å‡ºç›®å½• (é»˜è®¤: outputs)')

    # æ¨ç†é…ç½®
    parser.add_argument('--baseline_output_dir', type=str, default='baseline_result',
                        help='åŸºçº¿æ¨ç†è¾“å‡ºç›®å½• (é»˜è®¤: baseline_result)')
    parser.add_argument('--lora_output_dir', type=str, default='lora_result',
                        help='LoRA æ¨ç†è¾“å‡ºç›®å½• (é»˜è®¤: lora_result)')
    parser.add_argument('--lora_model_path', type=str, default='lora_model',
                        help='LoRA æ¨¡å‹ä¿å­˜è·¯å¾„ (é»˜è®¤: lora_model)')

    # æµç¨‹æ§åˆ¶
    parser.add_argument('--skip_model_check', action='store_true',
                        help='è·³è¿‡æ¨¡å‹æ£€æŸ¥æ­¥éª¤')
    parser.add_argument('--skip_data_split', action='store_true',
                        help='è·³è¿‡æ•°æ®åˆ’åˆ†æ­¥éª¤')
    parser.add_argument('--skip_baseline_inference', action='store_true',
                        help='è·³è¿‡è®­ç»ƒå‰è¯„ä¼°æ­¥éª¤')
    parser.add_argument('--skip_training', action='store_true',
                        help='è·³è¿‡è®­ç»ƒæ­¥éª¤')
    parser.add_argument('--skip_lora_inference', action='store_true',
                        help='è·³è¿‡è®­ç»ƒåè¯„ä¼°æ­¥éª¤')

    # è¾“å‡ºé…ç½®
    parser.add_argument('--summary_file', type=str, default='experiment_summary.json',
                        help='å®éªŒæ€»ç»“æ–‡ä»¶ (é»˜è®¤: experiment_summary.json)')

    args = parser.parse_args()

    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()

    # æ‰“å°æµç¨‹æ ‡é¢˜
    print_section("ğŸš€ DeepSeek OCR å®Œæ•´è®­ç»ƒå’Œè¯„ä¼°æµç¨‹", Color.HEADER)
    print(f"{Color.OKBLUE}å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}{Color.ENDC}")
    print(f"{Color.OKBLUE}æ•°æ®ç±»å‹: {args.data_type}{Color.ENDC}")
    print(f"{Color.OKBLUE}åŸºç¡€æ¨¡å‹: {args.model_dir}{Color.ENDC}")
    print(f"{Color.OKBLUE}LoRA æ¨¡å‹: {args.lora_model_path}{Color.ENDC}")

    try:
        # æ­¥éª¤ 1: æ£€æŸ¥æ¨¡å‹
        if not args.skip_model_check:
            if not step_1_check_model(args.model_dir, args.model_id, args.auto_download_model):
                raise RuntimeError("æ¨¡å‹æ£€æŸ¥å¤±è´¥")
        else:
            print(f"\n{Color.WARNING}âš  è·³è¿‡æ­¥éª¤ 1: æ¨¡å‹æ£€æŸ¥{Color.ENDC}")

        # æ­¥éª¤ 2: åˆ’åˆ†æ•°æ®
        if not args.skip_data_split:
            if not step_2_split_data(args.data_type, args.data_root, args.split_data_dir,
                                     args.train_ratio, args.split_seed):
                raise RuntimeError("æ•°æ®åˆ’åˆ†å¤±è´¥")
        else:
            print(f"\n{Color.WARNING}âš  è·³è¿‡æ­¥éª¤ 2: æ•°æ®åˆ’åˆ†{Color.ENDC}")

        # æ­¥éª¤ 3: è®­ç»ƒå‰è¯„ä¼°
        if not args.skip_baseline_inference:
            if not step_3_baseline_inference(args.data_type, args.model_dir, args.split_data_dir,
                                             args.baseline_output_dir):
                raise RuntimeError("è®­ç»ƒå‰è¯„ä¼°å¤±è´¥")
        else:
            print(f"\n{Color.WARNING}âš  è·³è¿‡æ­¥éª¤ 3: è®­ç»ƒå‰è¯„ä¼°{Color.ENDC}")

        # æ­¥éª¤ 4: è®­ç»ƒæ¨¡å‹
        if not args.skip_training:
            overrides = {}
            if args.data_type:
                overrides['data_type'] = args.data_type
            if args.max_steps:
                overrides['max_steps'] = args.max_steps
            if args.num_train_epochs:
                overrides['num_train_epochs'] = args.num_train_epochs
            if args.learning_rate:
                overrides['learning_rate'] = args.learning_rate
            if args.train_output_dir:
                overrides['output_dir'] = args.train_output_dir

            if not step_4_train_model(args.train_config, overrides):
                raise RuntimeError("æ¨¡å‹è®­ç»ƒå¤±è´¥")
        else:
            print(f"\n{Color.WARNING}âš  è·³è¿‡æ­¥éª¤ 4: æ¨¡å‹è®­ç»ƒ{Color.ENDC}")

        # æ­¥éª¤ 5: è®­ç»ƒåè¯„ä¼°
        if not args.skip_lora_inference:
            if not step_5_lora_inference(args.data_type, args.lora_model_path, args.model_dir,
                                         args.split_data_dir, args.lora_output_dir):
                raise RuntimeError("è®­ç»ƒåè¯„ä¼°å¤±è´¥")
        else:
            print(f"\n{Color.WARNING}âš  è·³è¿‡æ­¥éª¤ 5: è®­ç»ƒåè¯„ä¼°{Color.ENDC}")

        # æ­¥éª¤ 6: è¯„ä¼°å¹¶å¯¹æ¯”
        results = step_6_evaluate_and_compare(args.data_type, args.split_data_dir,
                                              args.baseline_output_dir, args.lora_output_dir)

        # ä¿å­˜å®éªŒæ€»ç»“
        config_summary = {
            'model_dir': args.model_dir,
            'data_type': args.data_type,
            'train_ratio': args.train_ratio,
            'lora_model_path': args.lora_model_path,
        }
        save_experiment_summary(config_summary, results, start_time, args.summary_file)

        # å®Œæˆ
        duration = time.time() - start_time
        print_section("âœ… å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸï¼", Color.OKGREEN)
        print(f"{Color.OKGREEN}æ€»è€—æ—¶: {duration:.2f} ç§’ ({duration/60:.2f} åˆ†é’Ÿ){Color.ENDC}")
        print(f"\n{Color.OKBLUE}ç»“æœä½ç½®:{Color.ENDC}")
        print(f"  - è®­ç»ƒå‰ç»“æœ: {args.baseline_output_dir}/test/")
        print(f"  - è®­ç»ƒåç»“æœ: {args.lora_output_dir}/test/")
        print(f"  - LoRA æ¨¡å‹: {args.lora_model_path}/")
        print(f"  - å®éªŒæ€»ç»“: {args.summary_file}")
        print()

    except Exception as e:
        print(f"\n{Color.FAIL}{'=' * 80}")
        print(f"âœ— æµç¨‹å¤±è´¥: {e}")
        print(f"{'=' * 80}{Color.ENDC}\n")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
