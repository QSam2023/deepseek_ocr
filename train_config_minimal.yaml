# æç®€è®­ç»ƒé…ç½® - ç”¨äºæµ‹è¯•å’Œæ‰¾å‡ºçœŸæ­£çš„æ€§èƒ½ç“¶é¢ˆ
# å…³é”®ä¼˜åŒ–ï¼šç¦ç”¨crop_modeï¼Œå‡å°å›¾åƒå°ºå¯¸ï¼Œç®€åŒ–å¤„ç†æµç¨‹

data:
  data_root: "ocr_data"
  split_data_dir: "ocr_data/splited_data"
  use_existing_split: true
  data_type: "table"  # åªæµ‹è¯•ä¸€ä¸ªä»»åŠ¡ï¼ŒåŠ å¿«æµ‹è¯•
  train_ratio: 0.8
  split_seed: 42

model:
  model_path: "./deepseek_ocr"
  load_in_4bit: false
  use_gradient_checkpointing: false  # ç¦ç”¨ä»¥æµ‹è¯•çº¯è®¡ç®—é€Ÿåº¦
  unsloth_force_compile: true

  lora:
    r: 8  # æœ€å° rank ç”¨äºæµ‹è¯•
    lora_alpha: 8
    lora_dropout: 0
    bias: "none"
    random_state: 3407
    use_rslora: false
    # åªè®­ç»ƒ QVï¼Œå‡å°‘è®¡ç®—é‡
    target_modules:
      - "q_proj"
      - "v_proj"

data_processing:
  # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šå‡å°å›¾åƒå°ºå¯¸
  image_size: 512     # ä» 640 é™åˆ° 512
  base_size: 768      # ä» 1024 é™åˆ° 768

  # ğŸ”¥ å…³é”®ä¼˜åŒ–ï¼šç¦ç”¨åŠ¨æ€è£å‰ªï¼ˆå¯èƒ½æ˜¯ä¸»è¦ç“¶é¢ˆï¼‰
  crop_mode: false

  train_on_responses_only: true

training:
  output_dir: "outputs_minimal"

  # ğŸ”¥ å°½å¯èƒ½å¤§çš„ batch size
  per_device_train_batch_size: 16
  gradient_accumulation_steps: 1

  warmup_steps: 0  # æµ‹è¯•æ—¶ä¸éœ€è¦
  max_steps: 20    # å¿«é€Ÿæµ‹è¯•

  learning_rate: 2e-4
  logging_steps: 1

  optim: "adamw_torch_fused"
  weight_decay: 0.01
  lr_scheduler_type: "constant"  # ç®€åŒ–
  seed: 3407

  # DataLoader ä¼˜åŒ–
  dataloader_num_workers: 8
  dataloader_prefetch_factor: 4
  dataloader_pin_memory: true
  dataloader_persistent_workers: true

  # ä¸ä¿å­˜æ£€æŸ¥ç‚¹ï¼ŒåŠ å¿«æµ‹è¯•
  save_strategy: "no"
  report_to: "none"

  # æ··åˆç²¾åº¦
  bf16: true
  fp16: false
  tf32: true

saving:
  lora_model_path: "lora_model_minimal"
  save_merged_model: false
