#!/usr/bin/env python3
"""
æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
ç”¨äºå¯¹æ¯”ä¼˜åŒ–å‰åçš„è®­ç»ƒæ€§èƒ½
"""

import os
import sys
import time
import json
import argparse
import subprocess
from datetime import datetime
from typing import Dict, List, Tuple


class Color:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'


def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{Color.HEADER}{'=' * 80}")
    print(f"{title}")
    print(f"{'=' * 80}{Color.ENDC}\n")


def run_benchmark(config_path: str, steps: int = 10) -> Dict:
    """è¿è¡ŒåŸºå‡†æµ‹è¯•"""
    print(f"\n{Color.OKBLUE}æµ‹è¯•é…ç½®: {config_path}{Color.ENDC}")
    print(f"{Color.OKBLUE}æµ‹è¯•æ­¥æ•°: {steps}{Color.ENDC}\n")

    cmd = [
        sys.executable, 'train_model.py',
        '--config', config_path,
        '--max_steps', str(steps)
    ]

    print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}\n")

    start_time = time.time()
    result = subprocess.run(cmd, capture_output=True, text=True)
    end_time = time.time()

    duration = end_time - start_time
    success = result.returncode == 0

    # è§£æè¾“å‡ºä¸­çš„æ€§èƒ½ä¿¡æ¯
    output = result.stdout + result.stderr

    benchmark_result = {
        'config': config_path,
        'steps': steps,
        'duration_seconds': duration,
        'success': success,
        'throughput_steps_per_second': steps / duration if success else 0,
        'avg_seconds_per_step': duration / steps if success else 0,
        'timestamp': datetime.now().isoformat()
    }

    if success:
        print(f"{Color.OKGREEN}âœ“ æµ‹è¯•å®Œæˆ{Color.ENDC}")
        print(f"  æ€»è€—æ—¶: {duration:.2f} ç§’")
        print(f"  å¹³å‡æ¯æ­¥: {duration/steps:.2f} ç§’")
        print(f"  ååé‡: {steps/duration:.2f} steps/ç§’")
    else:
        print(f"{Color.FAIL}âœ— æµ‹è¯•å¤±è´¥{Color.ENDC}")
        print(f"  é”™è¯¯è¾“å‡º: {result.stderr[:500]}")

    return benchmark_result


def check_gpu_stats() -> Dict:
    """æ£€æŸ¥ GPU çŠ¶æ€"""
    try:
        result = subprocess.run(
            ['nvidia-smi', '--query-gpu=name,memory.total,memory.used,utilization.gpu,power.draw,power.limit',
             '--format=csv,noheader,nounits'],
            capture_output=True,
            text=True,
            check=True
        )

        parts = result.stdout.strip().split(', ')

        return {
            'name': parts[0],
            'memory_total_mb': float(parts[1]),
            'memory_used_mb': float(parts[2]),
            'gpu_util_percent': float(parts[3]),
            'power_draw_w': float(parts[4]),
            'power_limit_w': float(parts[5])
        }
    except Exception as e:
        print(f"{Color.WARNING}âš  æ— æ³•è·å– GPU ä¿¡æ¯: {e}{Color.ENDC}")
        return {}


def compare_results(baseline: Dict, optimized: Dict):
    """å¯¹æ¯”åŸºå‡†å’Œä¼˜åŒ–ç»“æœ"""
    print_section("æ€§èƒ½å¯¹æ¯”")

    if not baseline['success'] or not optimized['success']:
        print(f"{Color.FAIL}æ— æ³•å¯¹æ¯”ï¼šéƒ¨åˆ†æµ‹è¯•å¤±è´¥{Color.ENDC}")
        return

    # è®¡ç®—æ”¹è¿›æ¯”ä¾‹
    speedup = baseline['duration_seconds'] / optimized['duration_seconds']
    throughput_improvement = (
        (optimized['throughput_steps_per_second'] - baseline['throughput_steps_per_second']) /
        baseline['throughput_steps_per_second'] * 100
    )

    print(f"{Color.BOLD}è®­ç»ƒé€Ÿåº¦:{Color.ENDC}")
    print(f"  åŸºå‡†é…ç½®: {baseline['avg_seconds_per_step']:.3f} ç§’/æ­¥")
    print(f"  ä¼˜åŒ–é…ç½®: {optimized['avg_seconds_per_step']:.3f} ç§’/æ­¥")
    print(f"  {Color.OKGREEN}åŠ é€Ÿæ¯”: {speedup:.2f}x{Color.ENDC}")

    print(f"\n{Color.BOLD}ååé‡:{Color.ENDC}")
    print(f"  åŸºå‡†é…ç½®: {baseline['throughput_steps_per_second']:.3f} steps/ç§’")
    print(f"  ä¼˜åŒ–é…ç½®: {optimized['throughput_steps_per_second']:.3f} steps/ç§’")
    print(f"  {Color.OKGREEN}æå‡: {throughput_improvement:+.1f}%{Color.ENDC}")

    print(f"\n{Color.BOLD}æ€»è€—æ—¶ ({baseline['steps']} æ­¥):{Color.ENDC}")
    print(f"  åŸºå‡†é…ç½®: {baseline['duration_seconds']:.2f} ç§’")
    print(f"  ä¼˜åŒ–é…ç½®: {optimized['duration_seconds']:.2f} ç§’")
    print(f"  {Color.OKGREEN}èŠ‚çœ: {baseline['duration_seconds'] - optimized['duration_seconds']:.2f} ç§’{Color.ENDC}")

    # æ€§èƒ½ç­‰çº§è¯„ä¼°
    print(f"\n{Color.BOLD}æ€§èƒ½è¯„ä¼°:{Color.ENDC}")
    if speedup >= 2.5:
        print(f"  {Color.OKGREEN}â˜…â˜…â˜…â˜…â˜… ä¼˜ç§€ - åŠ é€Ÿæ¯”è¾¾åˆ° {speedup:.1f}x{Color.ENDC}")
    elif speedup >= 2.0:
        print(f"  {Color.OKGREEN}â˜…â˜…â˜…â˜…â˜† è‰¯å¥½ - åŠ é€Ÿæ¯”è¾¾åˆ° {speedup:.1f}x{Color.ENDC}")
    elif speedup >= 1.5:
        print(f"  {Color.OKCYAN}â˜…â˜…â˜…â˜†â˜† ä¸­ç­‰ - åŠ é€Ÿæ¯”è¾¾åˆ° {speedup:.1f}x{Color.ENDC}")
    elif speedup >= 1.2:
        print(f"  {Color.WARNING}â˜…â˜…â˜†â˜†â˜† ä¸€èˆ¬ - åŠ é€Ÿæ¯”ä»… {speedup:.1f}x{Color.ENDC}")
    else:
        print(f"  {Color.FAIL}â˜…â˜†â˜†â˜†â˜† è¾ƒå·® - åŠ é€Ÿæ¯”ä»… {speedup:.1f}x{Color.ENDC}")
        print(f"  å»ºè®®æ£€æŸ¥é…ç½®æˆ–ç¡¬ä»¶çŠ¶æ€")


def save_results(baseline: Dict, optimized: Dict, output_file: str):
    """ä¿å­˜æµ‹è¯•ç»“æœ"""
    results = {
        'test_time': datetime.now().isoformat(),
        'baseline': baseline,
        'optimized': optimized,
        'gpu_info': check_gpu_stats()
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"\n{Color.OKGREEN}ç»“æœå·²ä¿å­˜: {output_file}{Color.ENDC}")


def main():
    parser = argparse.ArgumentParser(
        description="æ€§èƒ½åŸºå‡†æµ‹è¯• - å¯¹æ¯”ä¼˜åŒ–å‰åçš„è®­ç»ƒé€Ÿåº¦",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬æµ‹è¯•ï¼ˆ10æ­¥ï¼‰
  python benchmark_performance.py

  # æ›´é•¿çš„æµ‹è¯•ï¼ˆ50æ­¥ï¼‰
  python benchmark_performance.py --steps 50

  # åªæµ‹è¯•ä¼˜åŒ–é…ç½®
  python benchmark_performance.py --only-optimized

  # è‡ªå®šä¹‰é…ç½®å¯¹æ¯”
  python benchmark_performance.py \\
    --baseline-config my_config.yaml \\
    --optimized-config my_optimized_config.yaml
        """
    )

    parser.add_argument('--baseline-config', type=str, default='train_config.yaml',
                        help='åŸºå‡†é…ç½®æ–‡ä»¶ (é»˜è®¤: train_config.yaml)')
    parser.add_argument('--optimized-config', type=str, default='train_config_optimized.yaml',
                        help='ä¼˜åŒ–é…ç½®æ–‡ä»¶ (é»˜è®¤: train_config_optimized.yaml)')
    parser.add_argument('--steps', type=int, default=10,
                        help='æµ‹è¯•æ­¥æ•° (é»˜è®¤: 10)')
    parser.add_argument('--only-baseline', action='store_true',
                        help='åªæµ‹è¯•åŸºå‡†é…ç½®')
    parser.add_argument('--only-optimized', action='store_true',
                        help='åªæµ‹è¯•ä¼˜åŒ–é…ç½®')
    parser.add_argument('--output', type=str, default='benchmark_results.json',
                        help='ç»“æœä¿å­˜æ–‡ä»¶ (é»˜è®¤: benchmark_results.json)')
    parser.add_argument('--skip-comparison', action='store_true',
                        help='è·³è¿‡å¯¹æ¯”ï¼ˆåªè¿è¡Œæµ‹è¯•ï¼‰')

    args = parser.parse_args()

    print_section("ğŸš€ DeepSeek OCR æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print(f"{Color.OKBLUE}å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}{Color.ENDC}")

    # æ£€æŸ¥ GPU
    gpu_info = check_gpu_stats()
    if gpu_info:
        print(f"\n{Color.BOLD}GPU ä¿¡æ¯:{Color.ENDC}")
        print(f"  å‹å·: {gpu_info.get('name', 'Unknown')}")
        print(f"  æ˜¾å­˜: {gpu_info.get('memory_used_mb', 0):.0f}MB / "
              f"{gpu_info.get('memory_total_mb', 0):.0f}MB")
        print(f"  åˆ©ç”¨ç‡: {gpu_info.get('gpu_util_percent', 0):.0f}%")
        print(f"  åŠŸè€—: {gpu_info.get('power_draw_w', 0):.0f}W / "
              f"{gpu_info.get('power_limit_w', 0):.0f}W")

    baseline_result = None
    optimized_result = None

    try:
        # æµ‹è¯•åŸºå‡†é…ç½®
        if not args.only_optimized:
            print_section("ğŸ“Š æµ‹è¯•åŸºå‡†é…ç½®")
            if not os.path.exists(args.baseline_config):
                print(f"{Color.FAIL}é”™è¯¯: åŸºå‡†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ {args.baseline_config}{Color.ENDC}")
                sys.exit(1)
            baseline_result = run_benchmark(args.baseline_config, args.steps)

        # æµ‹è¯•ä¼˜åŒ–é…ç½®
        if not args.only_baseline:
            print_section("ğŸ“Š æµ‹è¯•ä¼˜åŒ–é…ç½®")
            if not os.path.exists(args.optimized_config):
                print(f"{Color.FAIL}é”™è¯¯: ä¼˜åŒ–é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ {args.optimized_config}{Color.ENDC}")
                sys.exit(1)
            optimized_result = run_benchmark(args.optimized_config, args.steps)

        # å¯¹æ¯”ç»“æœ
        if baseline_result and optimized_result and not args.skip_comparison:
            compare_results(baseline_result, optimized_result)

        # ä¿å­˜ç»“æœ
        if baseline_result or optimized_result:
            save_results(
                baseline_result or {},
                optimized_result or {},
                args.output
            )

        # æ€»ç»“
        print_section("âœ… æµ‹è¯•å®Œæˆ")
        print(f"{Color.OKGREEN}æ‰€æœ‰æµ‹è¯•å·²å®Œæˆ{Color.ENDC}\n")

        if baseline_result and optimized_result:
            speedup = baseline_result['duration_seconds'] / optimized_result['duration_seconds']
            print(f"{Color.BOLD}å…³é”®æŒ‡æ ‡:{Color.ENDC}")
            print(f"  ğŸš€ åŠ é€Ÿæ¯”: {Color.OKGREEN}{speedup:.2f}x{Color.ENDC}")

            if speedup >= 2.0:
                print(f"\n{Color.OKGREEN}âœ¨ ä¼˜åŒ–æ•ˆæœæ˜¾è‘—ï¼å»ºè®®ä½¿ç”¨ä¼˜åŒ–é…ç½®è¿›è¡Œè®­ç»ƒã€‚{Color.ENDC}")
            elif speedup >= 1.5:
                print(f"\n{Color.OKCYAN}ğŸ“ˆ ä¼˜åŒ–æœ‰ä¸€å®šæ•ˆæœï¼Œå¯è€ƒè™‘è¿›ä¸€æ­¥è°ƒä¼˜ã€‚{Color.ENDC}")
            else:
                print(f"\n{Color.WARNING}âš ï¸  ä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾ï¼Œå»ºè®®æ£€æŸ¥é…ç½®æˆ–ç³»ç»ŸçŠ¶æ€ã€‚{Color.ENDC}")

    except KeyboardInterrupt:
        print(f"\n\n{Color.WARNING}æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­{Color.ENDC}")
        sys.exit(1)
    except Exception as e:
        print(f"\n{Color.FAIL}æµ‹è¯•å¤±è´¥: {e}{Color.ENDC}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
